{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from confluent_kafka.avro import AvroConsumer\\nfrom confluent_kafka.avro.serializer import SerializerError\\n\\n\\nc = AvroConsumer({\\n    \\'bootstrap.servers\\': \\'_confluent-ksql-default_query_CSAS_PAGEVIEWS_FEMALE_LIKE_89_15\\',\\n    \\'group.id\\': \\'c\\',\\n    \\'schema.registry.url\\': \\'http://localhost:8081\\'})\\n\\nc.subscribe([\\'PAGEVIEWS_FEMALE\\'])\\n\\nwhile True:\\n    try:\\n        msg = c.poll(10)\\n\\n    except SerializerError as e:\\n        print(\"Message deserialization failed for {}: {}\".format(msg, e))\\n        break\\n\\n    if msg is None:\\n        continue\\n\\n    if msg.error():\\n        print(\"AvroConsumer error: {}\".format(msg.error()))\\n        continue\\n\\n    print(msg.value())\\n\\nc.close()'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from confluent_kafka.avro import AvroConsumer\n",
    "from confluent_kafka.avro.serializer import SerializerError\n",
    "\n",
    "\n",
    "c = AvroConsumer({\n",
    "    'bootstrap.servers': '_confluent-ksql-default_query_CSAS_PAGEVIEWS_FEMALE_LIKE_89_15',\n",
    "    'group.id': 'c',\n",
    "    'schema.registry.url': 'http://localhost:8081'})\n",
    "\n",
    "c.subscribe(['PAGEVIEWS_FEMALE'])\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        msg = c.poll(10)\n",
    "\n",
    "    except SerializerError as e:\n",
    "        print(\"Message deserialization failed for {}: {}\".format(msg, e))\n",
    "        break\n",
    "\n",
    "    if msg is None:\n",
    "        continue\n",
    "\n",
    "    if msg.error():\n",
    "        print(\"AvroConsumer error: {}\".format(msg.error()))\n",
    "        continue\n",
    "\n",
    "    print(msg.value())\n",
    "\n",
    "c.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from confluent_kafka import Consumer\\n\\nconf = {\\'bootstrap.servers\\': \"localhost:9092\",\\n        \\'group.id\\': \"_confluent-ksql-default_query_CTAS_PAGEVIEWS_REGIONS_17\",\\n        \\'auto.offset.reset\\': \\'smallest\\'}\\n\\nconsumer = Consumer(conf)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from confluent_kafka import Consumer\n",
    "\n",
    "conf = {'bootstrap.servers': \"localhost:9092\",\n",
    "        'group.id': \"_confluent-ksql-default_query_CTAS_PAGEVIEWS_REGIONS_17\",\n",
    "        'auto.offset.reset': 'smallest'}\n",
    "\n",
    "consumer = Consumer(conf)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"running = True\\nfrom confluent_kafka import KafkaError,KafkaException\\ndef basic_consume_loop(consumer, topics):\\n    try:\\n        consumer.subscribe(topics)\\n\\n        while running:\\n            msg = consumer.poll(timeout=1.0)\\n            if msg is None: continue\\n\\n            if msg.error():\\n                if msg.error().code() == KafkaError._PARTITION_EOF:\\n                    # End of partition event\\n                    sys.stderr.write('%% %s [%d] reached end at offset %d\\n' %\\n                                     (msg.topic(), msg.partition(), msg.offset()))\\n                elif msg.error():\\n                    raise KafkaException(msg.error())\\n            else:\\n                msg_process(msg)\\n    finally:\\n        # Close down consumer to commit final offsets.\\n        consumer.close()\\n\\ndef shutdown():\\n    running = False\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''running = True\n",
    "from confluent_kafka import KafkaError,KafkaException\n",
    "def basic_consume_loop(consumer, topics):\n",
    "    try:\n",
    "        consumer.subscribe(topics)\n",
    "\n",
    "        while running:\n",
    "            msg = consumer.poll(timeout=1.0)\n",
    "            if msg is None: continue\n",
    "\n",
    "            if msg.error():\n",
    "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                    # End of partition event\n",
    "                    sys.stderr.write('%% %s [%d] reached end at offset %d\\n' %\n",
    "                                     (msg.topic(), msg.partition(), msg.offset()))\n",
    "                elif msg.error():\n",
    "                    raise KafkaException(msg.error())\n",
    "            else:\n",
    "                msg_process(msg)\n",
    "    finally:\n",
    "        # Close down consumer to commit final offsets.\n",
    "        consumer.close()\n",
    "\n",
    "def shutdown():\n",
    "    running = False'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basic_consume_loop(consumer, ['pageviews'])\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''basic_consume_loop(consumer, ['pageviews'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
